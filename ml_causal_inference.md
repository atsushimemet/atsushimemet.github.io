# 機械学習モデルと因果推論

# 概要
　LightGBMやXGBoostといった勾配ブースティングフレームワークは予測のタスクに強みがある一方で、モデルの結果を解釈するタスクには難がある。モデルを解釈するために変数重要度やSHAPといった解釈ツールが準備されているが、これらの使用結果はモデルで使用された変数間の因果関係までを特定しないものの、往々にして変数間の関係性に因果関係があるような誤解を生んでしまうことがある。誤った因果関係が利害関係者に伝われば、結果を報告した者として責任を取らざるを得ない局面が発生する。このような状況を未然に防ぐためには、発生していまいがちな状況、解釈ツールの算出方法、そして本来あるべき使用方法について習熟する必要がある。本稿ではこれらについて述べていくこととする。

# 発生していまいがちな状況
## Scottの例
　発生していまいがちな状況を説明するために、Scott Lundberg（2021/05）による顧客のサブスクリプション更新予測の例を取り上げる。少し調査した後、解約を予測するために重要な8つの特徴を得ることに成功したとする（顧客への割引、投下した広告費、顧客の毎月の使用量、最後のアップグレード、顧客によって報告されたバグ、顧客とのインタラクション、顧客との営業電話、マクロ経済活動）。次にこれらの特徴を用いてXGBoostモデルを学習させ、顧客が契約期間満了時に契約を更新するかどうかを予測する。

```
X, y = user_retention_dataset()
model = fit_xgboost(X, y)
```

　XGBoostの顧客契約更新モデルを手に入れたら、SHAPのような解釈可能なツールを使ってそれが何を学習したかを調べ始めることができる。まず、モデル内の各特徴の重要度をプロットする。

```
explainer = shap.Explainer(model)
shap_values = explainer(X)
clust = shap.utils.hclust(X, y, linkage="single")
shap.plots.bar(shap_values, clustering=clust, clustering_cutoff=1)
```

![picture 1](images/dd0b7b0170d4bede312b7229252278cda0d33b631f1342d58b7b57a6b26c2897.png)  


　この棒グラフは、提供された割引、広告費、報告されたバグの数が、モデルによる顧客契約更新予測の上位3つの要因であることを示していおり、一見すると合理的である。（割引、広告費、バグはそれぞれ、契約更新に影響を与えそうだと考えることができる。）しかし、各特徴の値を変えることでモデルの予測にどのような影響があるかを深く掘り下げて見てみると、いくつかの直感的でないパターンがあることがわかる。


```
shap.plots.scatter(shap_values)
```

![picture 2](images/1add6a50bbcd92206ddae7a9cd65cd9089ca0719535ca76f27c768b0ae68edb7.png)  


　この図は、特徴の値を変えることで、モデルの更新確率予測にどのような影響を与えるかを示したものである。青い点が増加するパターンに従っている場合、その特徴が大きければ大きいほど、モデルの予測する更新確率が高くなることを意味する。散布図を見ると意外な発見があり、より多くのバグを報告したユーザーほど更新する傾向があり、割引率が高いユーザーほど、更新する可能性が低い。この結果の背景を知るために、直感的な説明を提供してくれる営業部門に話を聞きに行くと、直感的な説明が得られた。「製品を大切に使っているユーザーは、バグを報告したり、契約を更新したりする可能性が高い。また営業部門は、製品に興味を示さないと思われる顧客に対して高い値引きをする傾向があり、こうした顧客は解約率が高くなる。

　このような直感に反するようなモデルの関係性はゴールが何かによって問題となったり、問題ではなかったりする。このモデルの当初の目標は、顧客維持を予測することであった。これは、財務計画のために将来の収益を予測するようなプロジェクトに役立つ。より多くのバグを報告するユーザーは更新する可能性が高いので、バグと更新の関係をモデルに取り込むことは予測に有用である（このモデルがサンプル外(out of sample)でよい適合をする限り財務によい予測を提供できる）。したがってモデル中のこの関係の方向性を心配する必要はない。

　しかし、第2のチームが、より多くの顧客を維持するために取るべき行動を決定するという新たな目標を持って、この予測モデルを手に入れたとする。このチームは、Xの各特徴がYとどのように関連しているのか、Xを仮に1単位変化させたときに生じる反実仮想シナリオについても大いに関心がある。この場合、変数間の安定した相関関係を特定するだけではもはや十分ではない。このチームはXを操作することでYに変化が生じるかどうかに関心がある。顧客の契約更新確率を増やすために新しいバグを導入してほしいと伝えたときの技術責任者の顔を思い浮かべてください。

## 発生していまいがちな状況
　ここまでがScott(2021/05)による例であるが、当初は予測のために構築したモデルが、ビジネスにおけるアクションプラン設定のために使用される例は数多く存在する。そして、構築したモデルが勾配ブースティングフレームワークであるとき、SHAPが使用されることが多い。以降では、このSHAPの算出方法について理論的背景を確認しながら理解していくこととする。

# 解釈ツール（SHAP）の算出方法


# そして本来あるべき使用方法

# 参考文献
- [文献：Be Careful When Interpreting Predictive Models in Search of Causal Insights](https://towardsdatascience.com/be-careful-when-interpreting-predictive-models-in-search-of-causal-insights-e68626e664b6)
- [実装：Be careful when interpreting predictive models in search of causal insights](https://shap.readthedocs.io/en/latest/example_notebooks/overviews/Be%20careful%20when%20interpreting%20predictive%20models%20in%20search%20of%20causal%C2%A0insights.html)
